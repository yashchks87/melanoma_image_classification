{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_gpus = False\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        multiple_gpus = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../../melanoma_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv['updated_paths'] = train_csv['image_name'].apply(lambda x: '../../melanoma_data/jpeg/train/' + x + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(dataset, test_size = 0.01):\n",
    "    train, test = train_test_split(dataset, test_size = test_size, random_state=42)\n",
    "    train, val = train_test_split(train, test_size = test_size, random_state=42)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_exists(path):\n",
    "    if os.path.exists(path) == False:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(10) as p:\n",
    "    returns = list(p.map(check_if_exists, train_csv['updated_paths'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in returns:\n",
    "    if x == False:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    res50 = torchvision.models.resnet50()\n",
    "    res50.fc = nn.Linear(2048, 1)\n",
    "    return res50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepData(Dataset):\n",
    "    def __init__(self, csv_file, img_size):\n",
    "        self.csv_file = csv_file\n",
    "        self.paths = csv_file['updated_paths'].values.tolist()\n",
    "        self.labels = csv_file['target'].values.tolist()\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = torchvision.io.read_file(self.paths[idx])\n",
    "        img = torchvision.io.decode_jpeg(img)\n",
    "        img = torchvision.transforms.functional.resize(img, (self.img_size[0], self.img_size[1]))\n",
    "        img = img / 255\n",
    "        if self.labels[idx] == 'benign':\n",
    "            return img, torch.Tensor([0]).float()\n",
    "        else:\n",
    "            return img, torch.Tensor([1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_set = PrepData(train[:1000], img_size=(256, 256))\n",
    "val_set = PrepData(val, img_size=(256, 256))\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=10, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, num_workers=10, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a loss function here\n",
    "def bce_loss(inputs, targets):\n",
    "    sig = nn.Sigmoid()\n",
    "    bce_loss = nn.BCELoss()\n",
    "    inputs = sig(inputs)\n",
    "    loss = bce_loss(inputs, targets)\n",
    "    return loss\n",
    "\n",
    "def cal_prec(inputs, targets, thres=0.5):\n",
    "    # Formula for Prec = TP / (TP + FP)\n",
    "    sig = nn.Sigmoid()\n",
    "    inputs = torch.where(sig(inputs) > thres, 1.0, 0.0)\n",
    "    tp = torch.sum(torch.logical_and(inputs == 1.0, targets == 1.0))\n",
    "    fp = torch.sum(torch.logical_and(inputs == 1.0, targets == 0.0))\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def cal_rec(inputs, targets, thres=0.5):\n",
    "    # Formula for Prec = TP / (TP + FN)\n",
    "    sig = nn.Sigmoid()\n",
    "    inputs = torch.where(sig(inputs) > thres, 1.0, 0.0)\n",
    "    tp = torch.sum(torch.logical_and(inputs == 1.0, targets == 1.0))\n",
    "    fn = torch.sum(torch.logical_and(inputs == 0.0, targets == 1.0))\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(model, epochs, train_loader, val_loader, load_weights):\n",
    "    wandb.init(\n",
    "        project='melanoma-classification'\n",
    "    )\n",
    "    data_loaders = {\n",
    "        'train' : train_loader,\n",
    "        'val' : val_loader\n",
    "    }\n",
    "    # Define optimizer\n",
    "    # define how model sent to cuda\n",
    "    if load_weights != None:\n",
    "        model.load_state_dict(torch.load(load_weights)['model_state_dict'])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    if next(model.parameters()).is_cuda == False:\n",
    "        if multiple_gpus == True:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_prec, train_rec = 0.0, 0.0, 0.0\n",
    "        val_loss, val_prec, val_rec = 0.0, 0.0, 0.0\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss, running_prec, running_rec = 0.0, 0.0, 0.0\n",
    "            with tqdm(data_loaders[phase], unit='batch') as tepoch:\n",
    "                for img, label in tepoch:\n",
    "                    tepoch.set_description(f'Epoch: {epoch}')\n",
    "                    img = img.to(device)\n",
    "                    label = label.to(device)                \n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(img)\n",
    "                        loss = bce_loss(outputs, label)\n",
    "                        prec = cal_prec(outputs, label)\n",
    "                        rec = cal_prec(outputs, label)\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                    running_prec += prec.item()\n",
    "                    running_rec += rec.item()\n",
    "                    tepoch.set_postfix(loss = loss.item(), prec = prec.item(), rec = rec.item())\n",
    "            if phase == 'train':\n",
    "                train_loss += running_loss / len(data_loaders['train'])\n",
    "                train_prec += running_prec / len(data_loaders['train'])\n",
    "                train_rec += running_rec / len(data_loaders['train'])\n",
    "                print(f'For {phase} phase : {train_loss}')\n",
    "                print(f'For {phase} phase Prec : {train_prec}')\n",
    "                print(f'For {phase} phase Rec : {train_rec}')\n",
    "            else:\n",
    "                val_loss += val_loss / len(data_loaders['val'])\n",
    "                val_prec += running_prec / len(data_loaders['val'])\n",
    "                val_rec += running_rec / len(data_loaders['val'])\n",
    "                print(f'For {phase} phase : {val_loss}')\n",
    "                print(f'For {phase} phase Prec : {val_prec}')\n",
    "                print(f'For {phase} phase Rec : {val_rec}')\n",
    "        wandb.log({\n",
    "                    'train_loss' : train_loss,\n",
    "                    'val_loss' : val_loss,\n",
    "                    'train_prec' : train_prec,\n",
    "                    'val_prec' : val_prec,\n",
    "                    'train_rec' : train_rec,\n",
    "                    'val_rec' : val_rec\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:373lomhb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comic-universe-8</strong>: <a href=\"https://wandb.ai/yashchks87/melanoma-classification/runs/373lomhb\" target=\"_blank\">https://wandb.ai/yashchks87/melanoma-classification/runs/373lomhb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231130_165158-373lomhb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:373lomhb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5bd0582e424bc986bc2a5fc5d3a51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669513750002807, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Documents/melanoma_image_classification/notebooks/wandb/run-20231130_165249-2ivjjbe6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yashchks87/melanoma-classification/runs/2ivjjbe6\" target=\"_blank\">crimson-planet-9</a></strong> to <a href=\"https://wandb.ai/yashchks87/melanoma-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?batch/s]/home/paperspace/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: 0: 100%|██████████| 32/32 [00:39<00:00,  1.23s/batch, loss=0.0157, prec=1, rec=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train phase : 0.09427138129831292\n",
      "For train phase Prec : 1.0\n",
      "For train phase Rec : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 11/11 [00:13<00:00,  1.21s/batch, loss=0.0699, prec=1, rec=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For val phase : 0.0\n",
      "For val phase Prec : 1.0\n",
      "For val phase Rec : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 32/32 [00:33<00:00,  1.05s/batch, loss=0.00528, prec=1, rec=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train phase : 0.016081289082649164\n",
      "For train phase Prec : 1.0\n",
      "For train phase Rec : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:04<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B65.49.54.237/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_function(get_model(), \u001b[39m5\u001b[39;49m, train_loader, val_loader, \u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B65.49.54.237/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m running_loss, running_prec, running_rec \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B65.49.54.237/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(data_loaders[phase], unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m tepoch:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B65.49.54.237/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m tepoch:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B65.49.54.237/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         tepoch\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B65.49.54.237/home/paperspace/Documents/melanoma_image_classification/notebooks/torch_classification.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_function(get_model(), 5, train_loader, val_loader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
